{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490664e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOWorld\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c6b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOWorld(model='../models/yolov8s-world.pt')\n",
    "yolo = yolo.to(torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "key_layer_idx = {\n",
    "    # module 2-9 same as yolov8 \n",
    "    \"backbone_c2f1\": 2,\n",
    "    \"backbone_c2f2\": 4,\n",
    "    \"backbone_c2f3\": 6,\n",
    "    \"backbone_c2f4\": 8, \n",
    "    \"backbone_sppf\": 9,\n",
    "    # module changed\n",
    "    \"neck_c2f1\": 15,\n",
    "    \"neck_c2f2\": 19,\n",
    "    \"neck_c2f3\": 22,\n",
    "    \"detect_head\": 23\n",
    "}\n",
    "layers = {layer: yolo.model.model[idx] for layer, idx in key_layer_idx.items()}\n",
    "detect_head = layers['detect_head']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b0ea5",
   "metadata": {},
   "source": [
    "提取输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b662a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Hook: detect_head.cv2\n",
      "Registering Hook: detect_head.cv2.0\n",
      "Registering Hook: detect_head.cv2.0.0\n",
      "Registering Hook: detect_head.cv2.0.0.conv\n",
      "Registering Hook: detect_head.cv2.0.0.bn\n",
      "Registering Hook: detect_head.cv2.0.0.act\n",
      "Registering Hook: detect_head.cv2.0.1\n",
      "Registering Hook: detect_head.cv2.0.1.conv\n",
      "Registering Hook: detect_head.cv2.0.1.bn\n",
      "Registering Hook: detect_head.cv2.0.1.act\n",
      "Registering Hook: detect_head.cv2.0.2\n",
      "Registering Hook: detect_head.cv2.1\n",
      "Registering Hook: detect_head.cv2.1.0\n",
      "Registering Hook: detect_head.cv2.1.0.conv\n",
      "Registering Hook: detect_head.cv2.1.0.bn\n",
      "Registering Hook: detect_head.cv2.1.0.act\n",
      "Registering Hook: detect_head.cv2.1.1\n",
      "Registering Hook: detect_head.cv2.1.1.conv\n",
      "Registering Hook: detect_head.cv2.1.1.bn\n",
      "Registering Hook: detect_head.cv2.1.1.act\n",
      "Registering Hook: detect_head.cv2.1.2\n",
      "Registering Hook: detect_head.cv2.2\n",
      "Registering Hook: detect_head.cv2.2.0\n",
      "Registering Hook: detect_head.cv2.2.0.conv\n",
      "Registering Hook: detect_head.cv2.2.0.bn\n",
      "Registering Hook: detect_head.cv2.2.0.act\n",
      "Registering Hook: detect_head.cv2.2.1\n",
      "Registering Hook: detect_head.cv2.2.1.conv\n",
      "Registering Hook: detect_head.cv2.2.1.bn\n",
      "Registering Hook: detect_head.cv2.2.1.act\n",
      "Registering Hook: detect_head.cv2.2.2\n",
      "Registering Hook: detect_head.cv3\n",
      "Registering Hook: detect_head.cv3.0\n",
      "Registering Hook: detect_head.cv3.0.0\n",
      "Registering Hook: detect_head.cv3.0.0.conv\n",
      "Registering Hook: detect_head.cv3.0.0.bn\n",
      "Registering Hook: detect_head.cv3.0.0.act\n",
      "Registering Hook: detect_head.cv3.0.1\n",
      "Registering Hook: detect_head.cv3.0.1.conv\n",
      "Registering Hook: detect_head.cv3.0.1.bn\n",
      "Registering Hook: detect_head.cv3.0.1.act\n",
      "Registering Hook: detect_head.cv3.0.2\n",
      "Registering Hook: detect_head.cv3.1\n",
      "Registering Hook: detect_head.cv3.1.0\n",
      "Registering Hook: detect_head.cv3.1.0.conv\n",
      "Registering Hook: detect_head.cv3.1.0.bn\n",
      "Registering Hook: detect_head.cv3.1.0.act\n",
      "Registering Hook: detect_head.cv3.1.1\n",
      "Registering Hook: detect_head.cv3.1.1.conv\n",
      "Registering Hook: detect_head.cv3.1.1.bn\n",
      "Registering Hook: detect_head.cv3.1.1.act\n",
      "Registering Hook: detect_head.cv3.1.2\n",
      "Registering Hook: detect_head.cv3.2\n",
      "Registering Hook: detect_head.cv3.2.0\n",
      "Registering Hook: detect_head.cv3.2.0.conv\n",
      "Registering Hook: detect_head.cv3.2.0.bn\n",
      "Registering Hook: detect_head.cv3.2.0.act\n",
      "Registering Hook: detect_head.cv3.2.1\n",
      "Registering Hook: detect_head.cv3.2.1.conv\n",
      "Registering Hook: detect_head.cv3.2.1.bn\n",
      "Registering Hook: detect_head.cv3.2.1.act\n",
      "Registering Hook: detect_head.cv3.2.2\n",
      "Registering Hook: detect_head.dfl\n",
      "Registering Hook: detect_head.dfl.conv\n",
      "Registering Hook: detect_head.cv4\n",
      "Registering Hook: detect_head.cv4.0\n",
      "Registering Hook: detect_head.cv4.1\n",
      "Registering Hook: detect_head.cv4.2\n",
      "\n",
      "image 1/1 e:\\bmx\\DyFilterAttack\\DyFilterAttack\\analyzer\\..\\testset\\bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 52.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from DyFilterAttack.analyzer.utils import SaveFeatures\n",
    "save_feats = SaveFeatures()\n",
    "save_feats.register_hooks(module=detect_head, parent_path='detect_head', verbose=True)\n",
    "img_path = '../testset/bus.jpg'\n",
    "results = yolo.predict(img_path)\n",
    "detect_head_raw_feats = save_feats.get_features()\n",
    "\n",
    "nl = detect_head.nl\n",
    "nc, reg_max =  detect_head.nc, detect_head.reg_max\n",
    "no = nc + 4 * reg_max\n",
    "assert no == detect_head.no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eacfec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox: 50.064640045166016, 400.375, 248.49916076660156, 902.4866333007812, conf: tensor([0.9363], device='cuda:0'), class: person\n",
      "bbox: 222.50120544433594, 405.6936950683594, 344.2733154296875, 858.9097900390625, conf: tensor([0.9270], device='cuda:0'), class: person\n",
      "bbox: 669.1835327148438, 389.4619140625, 810.0, 875.4700317382812, conf: tensor([0.9181], device='cuda:0'), class: person\n",
      "bbox: 5.60137939453125, 229.0391387939453, 805.223388671875, 738.57177734375, conf: tensor([0.9020], device='cuda:0'), class: bus\n",
      "bbox: 0.0, 253.29833984375, 33.03541946411133, 324.5682373046875, conf: tensor([0.6973], device='cuda:0'), class: stop sign\n",
      "bbox: 0.0, 447.8066101074219, 75.65015411376953, 1044.215087890625, conf: tensor([0.6439], device='cuda:0'), class: person\n",
      "bbox: 0.0, 490.36016845703125, 77.55752563476562, 876.3672485351562, conf: tensor([0.4763], device='cuda:0'), class: person\n"
     ]
    }
   ],
   "source": [
    "# plot det result[B=0]\n",
    "result = results[0]\n",
    "for det in result.boxes:\n",
    "    xmin, ymin, xmax, ymax = det.xyxy[0]\n",
    "    conf = det.conf  # Confidence\n",
    "    cls = det.cls  # Class ID\n",
    "    class_name = result.names[cls[0].item()]\n",
    "    print(f\"bbox: {xmin}, {ymin}, {xmax}, {ymax}, conf: {conf}, class: {class_name}\")\n",
    "\n",
    "image = Image.fromarray(result.plot()[:, :, ::-1])\n",
    "image.show()\n",
    "image.save('result/bus_result.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc489239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2_raw_feats 0: torch.Size([1, 64, 80, 60])\n",
      "cv2_raw_feats 1: torch.Size([1, 64, 40, 30])\n",
      "cv2_raw_feats 2: torch.Size([1, 64, 20, 15])\n",
      "cv4_raw_feats 0: torch.Size([1, 80, 80, 60])\n",
      "cv4_raw_feats 1: torch.Size([1, 80, 40, 30])\n",
      "cv4_raw_feats 2: torch.Size([1, 80, 20, 15])\n",
      "cat_raw_feat: torch.Size([1, 144, 80, 60])\n",
      "flatten_raw_feats: torch.Size([1, 144, 6300])\n",
      "raw_box: torch.Size([1, 64, 6300])\n",
      "raw_cls: torch.Size([1, 80, 6300])\n",
      "dbox: torch.Size([1, 4, 6300])\n",
      "logit_cls: torch.Size([1, 80, 6300])\n",
      "sigmoid_cls: torch.Size([1, 80, 6300])\n"
     ]
    }
   ],
   "source": [
    "# process1 \n",
    "# text -> (B, nc, embed_dim)\n",
    "# image -> (B, embed_dim, H, W)\n",
    "# cv4 contrast(iamge, text) -> (B, nc, H, W)\n",
    "# cv2(image) -> (B, reg_max * 4, H, W)\n",
    "# cat_result -> (B, nc + reg_max * 4, H ,W) -> (B, no, H ,W)\n",
    "# x[i] -> cat_result[i] (i = 1, 2, nl)\n",
    "\n",
    "cv2_raw_feats = [detect_head_raw_feats[f'detect_head.cv2.{i}'] for i in range(nl)]\n",
    "cv4_raw_feats = [detect_head_raw_feats[f'detect_head.cv4.{i}'] for i in range(nl)]\n",
    "\n",
    "print(f'cv2_raw_feats {0}: {cv2_raw_feats[0].size()}')\n",
    "print(f'cv2_raw_feats {1}: {cv2_raw_feats[1].size()}')\n",
    "print(f'cv2_raw_feats {2}: {cv2_raw_feats[2].size()}')\n",
    "print(f'cv4_raw_feats {0}: {cv4_raw_feats[0].size()}')\n",
    "print(f'cv4_raw_feats {1}: {cv4_raw_feats[1].size()}')\n",
    "print(f'cv4_raw_feats {2}: {cv4_raw_feats[2].size()}')\n",
    "\n",
    "# process2 (_inference)\n",
    "# flat(x[i]) -> (B, no, H * W)\n",
    "# cat(x) -> (B, C, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "# split(x) -> bbox(B, 4 * reg_max, H0 * W0 + H1 * W1 + H2 * W2), cls(logit)(B, nc, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "# docode(bbox) -> dbox\n",
    "# logit(cls) -> sigmoid(cls)\n",
    "# y -> cat(dbox, cls)\n",
    "\n",
    "cat_raw_feats = [torch.cat((cv2_raw_feats[i], cv4_raw_feats[i]), 1) for i in range(nl)]\n",
    "flatten_raw_feats = torch.cat([cat_raw_feat.view(cat_raw_feats[0].shape[0], no, -1) for cat_raw_feat in cat_raw_feats], 2)\n",
    "raw_box = flatten_raw_feats[:, : reg_max * 4]\n",
    "raw_cls = flatten_raw_feats[:, reg_max * 4 :]\n",
    "\n",
    "dfl_feats = detect_head_raw_feats['detect_head.dfl']\n",
    "dbox = detect_head.decode_bboxes(dfl_feats, detect_head.anchors.unsqueeze(0)) * detect_head.strides\n",
    "# ! Attention: we need cls(logit) as y_det\n",
    "logit_cls = raw_cls\n",
    "sigmoid_cls = logit_cls.sigmoid()\n",
    "\n",
    "print(f'cat_raw_feat: {cat_raw_feats[0].size()}')           # (B, C, H * W)\n",
    "print(f'flatten_raw_feats: {flatten_raw_feats.size()}')     # (B, C, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'raw_box: {raw_box.size()}')                         # (B, 4 * reg_max, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'raw_cls: {raw_cls.size()}')                         # (B, nc, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'dbox: {dbox.size()}')                               # (B, 4,  H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'logit_cls: {logit_cls.size()}')                     # (B, nc, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'sigmoid_cls: {sigmoid_cls.size()}')                 # (B, nc, H0 * W0 + H1 * W1 + H2 * W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29317c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_det_orig_idx(shape)  : torch.Size([1, 7])\n",
      "y_det_orig(shape)      : torch.Size([1, 7])\n",
      "y_det_target_idx(shape): torch.Size([1, 7])\n",
      "y_det_target(shape)    : torch.Size([1, 7])\n",
      "y_det_orig_idx  : tensor([[ 0,  0,  0,  5, 11,  0,  0]], device='cuda:0')\n",
      "y_det_orig      : tensor([[ 2.6885,  2.5418,  2.4168,  2.2194,  0.8343,  0.5923, -0.0947]], device='cuda:0')\n",
      "y_det_target_idx: tensor([[77, 77, 16,  7, 25, 77, 77]], device='cuda:0')\n",
      "y_det_target    : tensor([[-8.1884, -9.1895, -9.1035, -3.3859, -4.7500, -6.7822, -4.1971]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# process3 (construct y_det_orig and y_de_target)\n",
    "# obtain the specific cls indices selected by non_max_suppression\n",
    "from ultralytics.utils import ops\n",
    "import numpy as np\n",
    "predictor = yolo.predictor\n",
    "preds = torch.cat([dbox, sigmoid_cls], 1)  # (B, 4+nc, N)\n",
    "\n",
    "detections, keep_idxs = ops.non_max_suppression(\n",
    "    preds,\n",
    "    predictor.args.conf,\n",
    "    predictor.args.iou,\n",
    "    predictor.args.classes,\n",
    "    predictor.args.agnostic_nms,\n",
    "    predictor.args.max_det,\n",
    "    nc=0 if predictor.args.task == \"detect\" else len(predictor.model.names),\n",
    "    end2end=getattr(predictor.model, \"end2end\", False),\n",
    "    rotated=predictor.args.task == \"obb\",\n",
    "    return_idxs=True,\n",
    ")\n",
    "\n",
    "num_nms_output = [idx.numel() for idx in keep_idxs]\n",
    "max_out = max(num_nms_output)\n",
    "\n",
    "y_det = raw_cls.new_zeros(raw_cls.shape[0], raw_cls.shape[1], max_out)\n",
    "for b, idx in enumerate(keep_idxs):  \n",
    "    if idx.numel() > 0:\n",
    "        y_det[b, :, :idx.numel()] = flatten_raw_feats[:raw_cls.shape[0], raw_box.shape[1]:, idx]\n",
    "        _det = raw_cls[:, :, idx]\n",
    "        assert np.all((_det==y_det).cpu().numpy())\n",
    "        \n",
    "\n",
    "first_max_cls_idx = torch.argmax(y_det, dim=1)  # (B, max_out)\n",
    "y_det_orig = y_det[torch.arange(y_det.shape[0]), first_max_cls_idx, torch.arange(y_det.shape[2])] # (B, max_out)\n",
    "\n",
    "_, topk_indices = torch.topk(y_det, 2, dim=1)\n",
    "second_max_cls_idx = topk_indices[:, 1]  # (B, max_out)\n",
    "y_det_target = y_det[torch.arange(y_det.shape[0]), second_max_cls_idx, torch.arange(y_det.shape[2])] # (B, max_out)\n",
    "\n",
    "print(f'y_det_orig_idx(shape)  : {first_max_cls_idx.shape}')\n",
    "print(f'y_det_orig(shape)      : {y_det_orig.shape}')\n",
    "print(f'y_det_target_idx(shape): {second_max_cls_idx.shape}')\n",
    "print(f'y_det_target(shape)    : {y_det_target.shape}')\n",
    "print(f'y_det_orig_idx  : {first_max_cls_idx}')\n",
    "print(f'y_det_orig      : {y_det_orig}')\n",
    "print(f'y_det_target_idx: {second_max_cls_idx}')\n",
    "print(f'y_det_target    : {y_det_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337aeca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
