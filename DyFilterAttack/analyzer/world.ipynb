{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490664e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOWorld\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34c6b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOWorld(model='../models/yolov8s-world.pt')\n",
    "yolo = yolo.to(torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "key_layer_idx = {\n",
    "    # module 2-9 same as yolov8 \n",
    "    \"backbone_c2f1\": 2,\n",
    "    \"backbone_c2f2\": 4,\n",
    "    \"backbone_c2f3\": 6,\n",
    "    \"backbone_c2f4\": 8, \n",
    "    \"backbone_sppf\": 9,\n",
    "    # module changed\n",
    "    \"neck_c2f1\": 15,\n",
    "    \"neck_c2f2\": 19,\n",
    "    \"neck_c2f3\": 22,\n",
    "    \"detect_head\": 23\n",
    "}\n",
    "layers = {layer: yolo.model.model[idx] for layer, idx in key_layer_idx.items()}\n",
    "detect_head = layers['detect_head']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b0ea5",
   "metadata": {},
   "source": [
    "提取输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b662a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Hook: detect_head.cv2\n",
      "Registering Hook: detect_head.cv2.0\n",
      "Registering Hook: detect_head.cv2.0.0\n",
      "Registering Hook: detect_head.cv2.0.0.conv\n",
      "Registering Hook: detect_head.cv2.0.0.bn\n",
      "Registering Hook: detect_head.cv2.0.0.act\n",
      "Registering Hook: detect_head.cv2.0.1\n",
      "Registering Hook: detect_head.cv2.0.1.conv\n",
      "Registering Hook: detect_head.cv2.0.1.bn\n",
      "Registering Hook: detect_head.cv2.0.1.act\n",
      "Registering Hook: detect_head.cv2.0.2\n",
      "Registering Hook: detect_head.cv2.1\n",
      "Registering Hook: detect_head.cv2.1.0\n",
      "Registering Hook: detect_head.cv2.1.0.conv\n",
      "Registering Hook: detect_head.cv2.1.0.bn\n",
      "Registering Hook: detect_head.cv2.1.0.act\n",
      "Registering Hook: detect_head.cv2.1.1\n",
      "Registering Hook: detect_head.cv2.1.1.conv\n",
      "Registering Hook: detect_head.cv2.1.1.bn\n",
      "Registering Hook: detect_head.cv2.1.1.act\n",
      "Registering Hook: detect_head.cv2.1.2\n",
      "Registering Hook: detect_head.cv2.2\n",
      "Registering Hook: detect_head.cv2.2.0\n",
      "Registering Hook: detect_head.cv2.2.0.conv\n",
      "Registering Hook: detect_head.cv2.2.0.bn\n",
      "Registering Hook: detect_head.cv2.2.0.act\n",
      "Registering Hook: detect_head.cv2.2.1\n",
      "Registering Hook: detect_head.cv2.2.1.conv\n",
      "Registering Hook: detect_head.cv2.2.1.bn\n",
      "Registering Hook: detect_head.cv2.2.1.act\n",
      "Registering Hook: detect_head.cv2.2.2\n",
      "Registering Hook: detect_head.cv3\n",
      "Registering Hook: detect_head.cv3.0\n",
      "Registering Hook: detect_head.cv3.0.0\n",
      "Registering Hook: detect_head.cv3.0.0.conv\n",
      "Registering Hook: detect_head.cv3.0.0.bn\n",
      "Registering Hook: detect_head.cv3.0.0.act\n",
      "Registering Hook: detect_head.cv3.0.1\n",
      "Registering Hook: detect_head.cv3.0.1.conv\n",
      "Registering Hook: detect_head.cv3.0.1.bn\n",
      "Registering Hook: detect_head.cv3.0.1.act\n",
      "Registering Hook: detect_head.cv3.0.2\n",
      "Registering Hook: detect_head.cv3.1\n",
      "Registering Hook: detect_head.cv3.1.0\n",
      "Registering Hook: detect_head.cv3.1.0.conv\n",
      "Registering Hook: detect_head.cv3.1.0.bn\n",
      "Registering Hook: detect_head.cv3.1.0.act\n",
      "Registering Hook: detect_head.cv3.1.1\n",
      "Registering Hook: detect_head.cv3.1.1.conv\n",
      "Registering Hook: detect_head.cv3.1.1.bn\n",
      "Registering Hook: detect_head.cv3.1.1.act\n",
      "Registering Hook: detect_head.cv3.1.2\n",
      "Registering Hook: detect_head.cv3.2\n",
      "Registering Hook: detect_head.cv3.2.0\n",
      "Registering Hook: detect_head.cv3.2.0.conv\n",
      "Registering Hook: detect_head.cv3.2.0.bn\n",
      "Registering Hook: detect_head.cv3.2.0.act\n",
      "Registering Hook: detect_head.cv3.2.1\n",
      "Registering Hook: detect_head.cv3.2.1.conv\n",
      "Registering Hook: detect_head.cv3.2.1.bn\n",
      "Registering Hook: detect_head.cv3.2.1.act\n",
      "Registering Hook: detect_head.cv3.2.2\n",
      "Registering Hook: detect_head.dfl\n",
      "Registering Hook: detect_head.dfl.conv\n",
      "Registering Hook: detect_head.cv4\n",
      "Registering Hook: detect_head.cv4.0\n",
      "Registering Hook: detect_head.cv4.1\n",
      "Registering Hook: detect_head.cv4.2\n",
      "\n",
      "image 1/1 e:\\bmx\\DyFilterAttack\\DyFilterAttack\\analyzer\\..\\testset\\bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 24.1ms\n",
      "Speed: 2.0ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from DyFilterAttack.analyzer.utils import SaveFeatures\n",
    "save_feats = SaveFeatures()\n",
    "save_feats.register_hooks(module=detect_head, parent_path='detect_head', verbose=True)\n",
    "img_path = '../testset/bus.jpg'\n",
    "results = yolo.predict(img_path)\n",
    "detect_head_raw_feats = save_feats.get_features()\n",
    "\n",
    "nl = detect_head.nl\n",
    "nc, reg_max =  detect_head.nc, detect_head.reg_max\n",
    "no = nc + 4 * reg_max\n",
    "assert no == detect_head.no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eacfec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox: 49.767730712890625, 400.7535400390625, 248.6864013671875, 903.1759033203125, conf: tensor([0.9302], device='cuda:0'), class: person\n",
      "bbox: 222.7787322998047, 405.39019775390625, 344.40283203125, 858.6336059570312, conf: tensor([0.9239], device='cuda:0'), class: person\n",
      "bbox: 669.021240234375, 388.7566833496094, 810.0, 875.3314819335938, conf: tensor([0.9147], device='cuda:0'), class: person\n",
      "bbox: 2.825357437133789, 228.2903289794922, 806.0357055664062, 738.6715087890625, conf: tensor([0.8791], device='cuda:0'), class: bus\n",
      "bbox: 0.0, 440.74639892578125, 75.3588638305664, 1035.9183349609375, conf: tensor([0.6437], device='cuda:0'), class: person\n",
      "bbox: 0.0, 251.178466796875, 32.303497314453125, 325.3988952636719, conf: tensor([0.4908], device='cuda:0'), class: stop sign\n",
      "bbox: 0.0, 479.6157531738281, 77.19075775146484, 877.2371826171875, conf: tensor([0.4771], device='cuda:0'), class: person\n"
     ]
    }
   ],
   "source": [
    "# plot det result[B=0]\n",
    "result = results[0]\n",
    "for det in result.boxes:\n",
    "    xmin, ymin, xmax, ymax = det.xyxy[0]\n",
    "    conf = det.conf  # Confidence\n",
    "    cls = det.cls  # Class ID\n",
    "    class_name = result.names[cls[0].item()]\n",
    "    print(f\"bbox: {xmin}, {ymin}, {xmax}, {ymax}, conf: {conf}, class: {class_name}\")\n",
    "\n",
    "image = Image.fromarray(result.plot()[:, :, ::-1])\n",
    "image.show()\n",
    "image.save('result/bus_result.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc489239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2_raw_feats 0: torch.Size([1, 64, 80, 60])\n",
      "cv2_raw_feats 1: torch.Size([1, 64, 40, 30])\n",
      "cv2_raw_feats 2: torch.Size([1, 64, 20, 15])\n",
      "cv4_raw_feats 0: torch.Size([1, 80, 80, 60])\n",
      "cv4_raw_feats 1: torch.Size([1, 80, 40, 30])\n",
      "cv4_raw_feats 2: torch.Size([1, 80, 20, 15])\n",
      "cat_raw_feat: torch.Size([1, 144, 80, 60])\n",
      "flatten_raw_feats: torch.Size([1, 144, 6300])\n",
      "raw_box: torch.Size([1, 64, 6300])\n",
      "raw_cls: torch.Size([1, 80, 6300])\n",
      "dbox: torch.Size([1, 4, 6300])\n",
      "logit_cls: torch.Size([1, 80, 6300])\n",
      "sigmoid_cls: torch.Size([1, 80, 6300])\n"
     ]
    }
   ],
   "source": [
    "# process1 \n",
    "# text -> (B, nc, embed_dim)\n",
    "# image -> (B, embed_dim, H, W)\n",
    "# cv4 contrast(iamge, text) -> (B, nc, H, W)\n",
    "# cv2(image) -> (B, reg_max * 4, H, W)\n",
    "# cat_result -> (B, nc + reg_max * 4, H ,W) -> (B, no, H ,W)\n",
    "# x[i] -> cat_result[i] (i = 1, 2, nl)\n",
    "\n",
    "cv2_raw_feats = [detect_head_raw_feats[f'detect_head.cv2.{i}'] for i in range(nl)]\n",
    "cv4_raw_feats = [detect_head_raw_feats[f'detect_head.cv4.{i}'] for i in range(nl)]\n",
    "\n",
    "print(f'cv2_raw_feats {0}: {cv2_raw_feats[0].size()}')\n",
    "print(f'cv2_raw_feats {1}: {cv2_raw_feats[1].size()}')\n",
    "print(f'cv2_raw_feats {2}: {cv2_raw_feats[2].size()}')\n",
    "print(f'cv4_raw_feats {0}: {cv4_raw_feats[0].size()}')\n",
    "print(f'cv4_raw_feats {1}: {cv4_raw_feats[1].size()}')\n",
    "print(f'cv4_raw_feats {2}: {cv4_raw_feats[2].size()}')\n",
    "\n",
    "# process2 (_inference)\n",
    "# flat(x[i]) -> (B, no, H * W)\n",
    "# cat(x) -> (B, C, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "# split(x) -> bbox(B, 4 * reg_max, H0 * W0 + H1 * W1 + H2 * W2), cls(logit)(B, nc, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "# docode(bbox) -> dbox\n",
    "# logit(cls) -> sigmoid(cls)\n",
    "# y -> cat(dbox, cls)\n",
    "\n",
    "cat_raw_feats = [torch.cat((cv2_raw_feats[i], cv4_raw_feats[i]), 1) for i in range(nl)]\n",
    "flatten_raw_feats = torch.cat([cat_raw_feat.view(cat_raw_feats[0].shape[0], no, -1) for cat_raw_feat in cat_raw_feats], 2)\n",
    "raw_box = flatten_raw_feats[:, : reg_max * 4]\n",
    "raw_cls = flatten_raw_feats[:, reg_max * 4 :]\n",
    "\n",
    "dfl_feats = detect_head_raw_feats['detect_head.dfl']\n",
    "dbox = detect_head.decode_bboxes(dfl_feats, detect_head.anchors.unsqueeze(0)) * detect_head.strides\n",
    "# ! Attention: we need cls(logit) as y_det\n",
    "logit_cls = raw_cls\n",
    "sigmoid_cls = logit_cls.sigmoid()\n",
    "\n",
    "print(f'cat_raw_feat: {cat_raw_feats[0].size()}')           # (B, C, H * W)\n",
    "print(f'flatten_raw_feats: {flatten_raw_feats.size()}')     # (B, C, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'raw_box: {raw_box.size()}')                         # (B, 4 * reg_max, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'raw_cls: {raw_cls.size()}')                         # (B, nc, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'dbox: {dbox.size()}')                               # (B, 4,  H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'logit_cls: {logit_cls.size()}')                     # (B, nc, H0 * W0 + H1 * W1 + H2 * W2)\n",
    "print(f'sigmoid_cls: {sigmoid_cls.size()}')                 # (B, nc, H0 * W0 + H1 * W1 + H2 * W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29317c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[ 2.9668e+01,  2.3726e+02,  1.4726e+02,  5.3481e+02,  9.3635e-01,  0.0000e+00],\n",
      "        [ 1.3185e+02,  2.4041e+02,  2.0401e+02,  5.0898e+02,  9.2702e-01,  0.0000e+00],\n",
      "        [ 3.9655e+02,  2.3079e+02,  4.8004e+02,  5.1880e+02,  9.1810e-01,  0.0000e+00],\n",
      "        [ 3.3193e+00,  1.3573e+02,  4.7717e+02,  4.3767e+02,  9.0198e-01,  5.0000e+00],\n",
      "        [-1.8368e-02,  1.5010e+02,  1.9577e+01,  1.9234e+02,  6.9726e-01,  1.1000e+01],\n",
      "        [-1.9777e-01,  2.6537e+02,  4.4830e+01,  6.1879e+02,  6.4389e-01,  0.0000e+00],\n",
      "        [-9.2316e-03,  2.9058e+02,  4.5960e+01,  5.1933e+02,  4.7633e-01,  0.0000e+00]], device='cuda:0')], [tensor([6197, 6185, 6223, 6126, 5100, 6165, 5610], device='cuda:0')])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.utils import ops\n",
    "predictor = yolo.predictor\n",
    "preds = torch.cat([dbox, sigmoid_cls], 1)  # (B, 4+nc, N)\n",
    "\n",
    "detections = ops.non_max_suppression(\n",
    "    preds,\n",
    "    predictor.args.conf,\n",
    "    predictor.args.iou,\n",
    "    predictor.args.classes,\n",
    "    predictor.args.agnostic_nms,\n",
    "    predictor.args.max_det,\n",
    "    nc=0 if predictor.args.task == \"detect\" else len(predictor.model.names),\n",
    "    end2end=getattr(predictor.model, \"end2end\", False),\n",
    "    rotated=predictor.args.task == \"obb\",\n",
    "    return_idxs=save_feats,\n",
    ")\n",
    "\n",
    "print(detections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
