#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
get_attack_meta.py
~~~~~~~~~~~~~~~~~~
üéØ ÁîüÊàêÈíàÂØπ YOLOWorld ÁöÑÊîªÂáªÂÖÉÊï∞ÊçÆ attack_meta.json
   - Êï∞ÊçÆÊ∫ê: LVIS-v1 val (Ê†áÊ≥®) + COCO2017 val ÂõæÂÉè
   - ËøáÊª§ËßÑÂàô:
       1) YOLOWorld Âú® conf > conf_thres Êó∂Ê£ÄÂá∫ >=1 ‰∏™Ê°Ü
       2) ËØ•Ê°ÜÁöÑ Top-1 ‰∏é Top-2 Á±ªÂà´‰∏çÂêåÔºå‰∏î logit_1 - logit_2 > margin_pre
"""

import argparse, json, os, shutil, tarfile, zipfile, tempfile, urllib.request
from pathlib import Path
from typing import Dict, List, Tuple
import urllib.request, shutil, time, json

import numpy as np
import torch
from ultralytics.utils import ops
from PIL import Image
from tqdm import tqdm
from ultralytics import YOLOWorld


# --------------------------------------------------------------------------- #
#                               ‰∏ãËΩΩÂ∑•ÂÖ∑                                       #
# --------------------------------------------------------------------------- #
_COCO_VAL_URL = "http://images.cocodataset.org/zips/val2017.zip"
_LVIS_VAL_JSON = "https://storage.googleapis.com/sfr-vision-language-research/LVIS/lvis_v1_val.json"
# --- Â§áÁî®ÈïúÂÉè URL ---
_LVIS_VAL_JSON_MIRRORS = [
    # HuggingFace
    "https://huggingface.co/datasets/visual_genome/LVIS/resolve/main/lvis_v1_val.json",
    # GitHub raw
    "https://raw.githubusercontent.com/zhangxiaosong18/LVIS-dataset/master/lvis_v1_val.json",
]


def download(url: str, save_path: Path, desc: str = "", mirrors: list[str] | None = None) -> None:
    """Â∏¶ UA + ÈïúÂÉèÈáçËØïÁöÑ‰∏ãËΩΩÂô®"""
    save_path.parent.mkdir(parents=True, exist_ok=True)
    if save_path.exists():
        print(f"[‚úì] {desc or save_path.name} Â∑≤Â≠òÂú®ÔºåË∑≥Ëøá‰∏ãËΩΩ")
        return

    urls = [url] + (mirrors or [])
    for idx, u in enumerate(urls, 1):
        try:
            print(f"‚Üì ({idx}/{len(urls)}) Ê≠£Âú®‰∏ãËΩΩ {desc or u}")
            req = urllib.request.Request(
                u,
                headers={"User-Agent": "Mozilla/5.0"},  # Ê∑ªÂä† UA ÁªïËøá 403
            )
            with urllib.request.urlopen(req) as resp, open(save_path, "wb") as f:
                shutil.copyfileobj(resp, f)
            print(f"[‚úì] ‰∏ãËΩΩÂÆåÊàê -> {save_path}")
            return
        except urllib.error.HTTPError as e:
            print(f"[√ó] HTTP {e.code} - {e.reason}ÔºåÂ∞ùËØï‰∏ã‰∏Ä‰∏™ÈïúÂÉè...")
        except Exception as e:
            print(f"[√ó] ‰∏ãËΩΩÂ§±Ë¥•: {e}ÔºåÂ∞ùËØï‰∏ã‰∏Ä‰∏™ÈïúÂÉè...")
        time.sleep(1)

    raise RuntimeError(f"ÊâÄÊúâÈïúÂÉèÂùá‰∏ãËΩΩÂ§±Ë¥•ÔºåËØ∑ÊâãÂä®‰∏ãËΩΩ {desc or url} Âà∞ {save_path}")


def extract_zip(zip_path: Path, extract_to: Path):
    print(f"‚Ä¢ Ê≠£Âú®Ëß£Âéã {zip_path.name} ...")
    with zipfile.ZipFile(zip_path, "r") as zf:
        zf.extractall(extract_to)
    print(f"[‚úì] Ëß£ÂéãÂÆåÊàê")


# --------------------------------------------------------------------------- #
#                                ÂÖÉÊï∞ÊçÆÁîüÊàê                                   #
# --------------------------------------------------------------------------- #
def coco_val_images(root: Path) -> List[Path]:
    """ËøîÂõû COCO val2017 ‰∏≠ÊâÄÊúâ .jpg Ë∑ØÂæÑ"""
    img_dir = root / "val2017"
    if not img_dir.exists():
        raise FileNotFoundError(f"{img_dir} ‰∏çÂ≠òÂú®ÔºåËØ∑Ê£ÄÊü•Ëß£Âéã")
    return sorted(img_dir.glob("*.jpg"))


def load_image(path: Path, size: int = 640) -> torch.Tensor:
    """Âä†ËΩΩÂπ∂ letterbox resize Âà∞ size √ó sizeÔºåËøîÂõû tensor(B=1,C,H,W) ‚àà[0,1]"""
    im = Image.open(path).convert("RGB")
    im = im.resize((size, size))
    arr = np.array(im).astype(np.float32) / 255.0  # H,W,C
    arr = arr.transpose(2, 0, 1)  # C,H,W
    return torch.from_numpy(arr).unsqueeze(0)  # 1,C,H,W


@torch.no_grad()
def run_world_on_image(model, img_tensor, conf_thres=0.25):
    """ËøîÂõû (pred_logits, det_indices)"""
    preds, _ = model.model(img_tensor)  # (B, 4+nc, N)
    model.predictor = model._smart_load("predictor")(_callbacks=model.callbacks)
    model.predictor.setup_model(model=model.model, verbose=False)
    predictor = model.predictor
    predictor = model.predictor
    logits = preds[:, 4:, :]  # (B, nc, N)
    # NMS (Ultralytics util)
    detections, keep_idxs = ops.non_max_suppression(
        preds,
        conf_thres,
        predictor.args.iou,
        predictor.args.classes,
        predictor.args.agnostic_nms,
        predictor.args.max_det,
        nc=0 if predictor.args.task == "detect" else len(predictor.model.names),
        end2end=getattr(predictor.model, "end2end", False),
        rotated=predictor.args.task == "obb",
        return_idxs=True,
    )

    return logits[0], keep_idxs[0]  # (nc,N)  &  idx Tensor(k,)


def build_attack_meta(
    world,
    img_paths: List[Path],
    out_json: Path,
    conf_thres: float = 0.25,
    margin_pre: float = 0.0,
) -> None:
    """
    Êé®ÁêÜ + ËøáÊª§ÔºåÁîüÊàê attack_meta.json
    """
    recs: List[Dict] = []
    pbar = tqdm(img_paths, desc="Scanning LVIS-val")
    for p in pbar:
        img_t = load_image(p).to(world.device)
        logits, keep_idx = run_world_on_image(world, img_t, conf_thres)  # (nc,N)  keep_idx shape(k,)
        if keep_idx.numel() == 0:
            continue

        # Âèñ Top-2 logits per det
        top2_vals, top2_ids = logits[:, keep_idx].topk(2, dim=0)  # (2, k)
        top1, top2 = top2_vals[0], top2_vals[1]  # shape (k,)
        # Êù°‰ª∂: top1 - top2 > margin_pre ‰∏îÁ±ªÂà´‰∏çÂêå
        ok_mask = (top1 - top2 > margin_pre) & (top2_ids[0] != top2_ids[1])
        if not ok_mask.any():
            continue

        # Âè™‰øùÂ≠òÊª°Ë∂≥Êù°‰ª∂ÁöÑ det Á¥¢Âºï
        sel = keep_idx[ok_mask.nonzero(as_tuple=True)[0]]
        recs.append({"image": str(p.relative_to(p.parents[1])), "det_ids": sel.tolist()})  # val2017/000000.jpg

        pbar.set_postfix(kept=len(recs))

    print(f"[‚úì] ÊúÄÁªàÂèØÊîªÂáªÂõæÂÉèÊï∞: {len(recs)}")
    out_json.write_text(json.dumps(recs, indent=2), encoding="utf-8")


# --------------------------------------------------------------------------- #
#                                   ‰∏ªÂáΩÊï∞                                    #
# --------------------------------------------------------------------------- #
def main():
    parser = argparse.ArgumentParser("Generate attack_meta.json for YOLOWorld on LVIS-val")
    parser.add_argument("--save-dir", default="./dataset/LVIS", type=Path, help="Êï∞ÊçÆÂèä meta ‰øùÂ≠òÊ†πÁõÆÂΩï")
    parser.add_argument("--model", required=True, type=Path, help="YOLOWorld checkpoint Ë∑ØÂæÑ (*.pt / *.yaml)")
    parser.add_argument("--img-size", default=640, type=int, help="Êé®ÁêÜÂàÜËæ®Áéá")
    parser.add_argument("--conf", default=0.25, type=float, help="NMS ÁΩÆ‰ø°Â∫¶Èòà")
    parser.add_argument("--margin-pre", default=0.0, type=float, help="Top1-Top2 logit Â∑ÆÂÄº > margin ÊâçËÆ§‰∏∫ÂèØÊîªÂáª")
    args = parser.parse_args()

    # ---------------- download & prepare dataset ---------------- #
    coco_zip = args.save_dir / "val2017.zip"
    coco_root = args.save_dir
    lvis_json = args.save_dir / "lvis_v1_val.json"

    download(_COCO_VAL_URL, coco_zip, "COCO val2017 images")
    if not (coco_root / "val2017").exists():
        extract_zip(coco_zip, coco_root)

    download(
        _LVIS_VAL_JSON,
        lvis_json,
        "LVIS val annotation",
        mirrors=_LVIS_VAL_JSON_MIRRORS,
    )

    # ---------------- load model ---------------- #
    world = YOLOWorld(args.model)
    world.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
    world.model.eval()
    print(f"[‚úì] YOLOWorld loaded: {args.model}")

    # ---------------- scan & build meta ---------------- #
    img_paths = coco_val_images(coco_root)
    out_json = args.save_dir / "attack_meta.json"
    build_attack_meta(
        world,
        img_paths,
        out_json,
        conf_thres=args.conf,
        margin_pre=args.margin_pre,
    )
    print(f"[+] attack_meta.json saved to {out_json.resolve()}")


if __name__ == "__main__":
    main()


# python DyFilterAttack/scripts/get_attack_meta.py --model DyFilterAttack/models/yolov8s-world.pt --save-dir DyFilterAttack/testset/lvis_data --conf 0.25 --margin-pre 0.0
