{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 84, 8400])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "# definition of \"net\"\n",
    "device = torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "yolo = YOLO(model='../models/yolov8n.pt')\n",
    "yolo_model = yolo.model\n",
    "yolo_model = yolo_model.to(device=device) # type: ignore\n",
    "\n",
    "# automatic preprocess and postprocess in YOLO object\n",
    "# img tensor\n",
    "img = cv2.imread(filename=\"../images/puppies.jpg\")\n",
    "img = cv2.resize(src=img, dsize=(640, 640))  # 输入尺寸需与模型训练时一致\n",
    "img_tensor = torch.from_numpy(img.transpose(2, 0, 1)/255).unsqueeze(dim=0).to(device=device, dtype=torch.float32)\n",
    "\n",
    "yolo_model.eval()\n",
    "yolo_output = yolo_model(img_tensor)[0]\n",
    "# torch.Size([1, 84, 8400])\n",
    "# 8400: (80×80+40×40+20×20)×84=(6400+1600+400)×84=8400×84\n",
    "#   84: (x, y, w, h, classes_scores[80])=1+1+1+1+80\n",
    "print(yolo_output.size())\n",
    "\n",
    "# 将输出重组为 [batch, anchors, (4+1+classes), h, w]\n",
    "batch_size, channels, num_boxes = yolo_output.shape\n",
    "num_anchors = channels - 5\n",
    "boxes = yolo_output[:, :4, :]          # [1, 4, 8400] → 4坐标\n",
    "conf = yolo_output[:, 4:5, :]          # [1, 1, 8400] → 置信度\n",
    "cls_probs = yolo_output[:, 5:, :]      # [1, num_classes, 8400] → 类别概率\n",
    "\n",
    "# print(yolo_output.size())\n",
    "\n",
    "# batch_size, channels, h, w = yolo_output.shape\n",
    "# num_anchors = 3  # 每个位置有3个锚框\n",
    "# orgi_pred = yolo_output.view(batch_size, num_anchors, -1, h, w).view(batch_size, num_anchors, )\n",
    "# print(orgi_pred.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_box_output(yolo_output, conf_threshold=0.5):\n",
    "    # 输入：YOLOv8的原始输出（多尺度检测头张量）\n",
    "    # 输出：置信度最高的目标框的原始输出（未经过NMS和sigmoid）\n",
    "    boxes = [out.orig_img for out in yolo_output]\n",
    "    for out in boxes:  # 遍历多尺度检测头\n",
    "        print(out.shape)\n",
    "        bs, na, h, w, nc = out.shape  # [1, 3, 80, 80, 85]等\n",
    "        out = out.view(bs, na, h*w, nc)  # 展平空间维度为[1, 3, 6400, 85]\n",
    "        for i in range(na):  # 遍历每个锚框\n",
    "            obj_conf = out[0, i, :, 4]  # 目标置信度（未sigmoid）\n",
    "            class_conf, class_idx = out[0, i, :, 5:].max(dim=1)  # 类别置信度（未sigmoid）\n",
    "            total_conf = obj_conf.sigmoid() * class_conf.sigmoid()  # 最终置信度（目标存在且类别的概率）\n",
    "            # 筛选置信度>阈值的框\n",
    "            mask = total_conf > conf_threshold\n",
    "            if mask.any():\n",
    "                max_idx = total_conf[mask].argmax()  # 置信度最高的框\n",
    "                target_out = out[0, i, mask][max_idx]  # 该框的原始输出（85维）\n",
    "                return target_out  # 返回该框的原始输出（用于梯度计算）\n",
    "    return None  # 无有效目标框\n",
    "\n",
    "get_target_box_output(yolo_output=yolo_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import copy\n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "\n",
    "\n",
    "def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=50):\n",
    "    \"\"\"\n",
    "    :param image: Image of size HxWx3\n",
    "    :param net: network (input: images, output: values of activation **BEFORE** softmax).\n",
    "    :param num_classes: num_classes (limits the number of classes to test against, by default = 10)\n",
    "    :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
    "    :param max_iter: maximum number of iterations for deepfool (default = 50)\n",
    "    :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
    "    \"\"\"\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "        print(\"Using GPU\")\n",
    "        image = image.cuda()\n",
    "        net = net.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    f_image = net.forward(Variable(image[None, :, :, :], requires_grad=True)).data.cpu().numpy().flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = Variable(pert_image[None, :], requires_grad=True)\n",
    "    fs = net.forward(x)\n",
    "    fs_list = [fs[0, I[k]] for k in range(num_classes)]\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            zero_gradients(x)\n",
    "\n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k) / np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i = (pert + 1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        if is_cuda:\n",
    "            pert_image = image + (1 + overshoot) * torch.from_numpy(r_tot).cuda()\n",
    "        else:\n",
    "            pert_image = image + (1 + overshoot) * torch.from_numpy(r_tot)\n",
    "\n",
    "        x = Variable(pert_image, requires_grad=True)\n",
    "        fs = net.forward(x)\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    r_tot = (1 + overshoot) * r_tot\n",
    "\n",
    "    return r_tot, loop_i, label, k_i, pert_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "net = models.resnet34(pretrained=True)\n",
    "\n",
    "# Switch to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "im_orig = Image.open('test_im2.jpg')\n",
    "\n",
    "mean = [ 0.485, 0.456, 0.406 ]\n",
    "std = [ 0.229, 0.224, 0.225 ]\n",
    "\n",
    "\n",
    "# Remove the mean\n",
    "im = transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std)])(im_orig)\n",
    "\n",
    "r, loop_i, label_orig, label_pert, pert_image = deepfool(im, net)\n",
    "\n",
    "labels = open(os.path.join('synset_words.txt'), 'r').read().split('\\n')\n",
    "\n",
    "str_label_orig = labels[np.int(label_orig)].split(',')[0]\n",
    "str_label_pert = labels[np.int(label_pert)].split(',')[0]\n",
    "\n",
    "print(\"Original label = \", str_label_orig)\n",
    "print(\"Perturbed label = \", str_label_pert)\n",
    "\n",
    "def clip_tensor(A, minv, maxv):\n",
    "    A = torch.max(A, minv*torch.ones(A.shape))\n",
    "    A = torch.min(A, maxv*torch.ones(A.shape))\n",
    "    return A\n",
    "\n",
    "clip = lambda x: clip_tensor(x, 0, 255)\n",
    "\n",
    "tf = transforms.Compose([transforms.Normalize(mean=[0, 0, 0], std=map(lambda x: 1 / x, std)),\n",
    "                        transforms.Normalize(mean=map(lambda x: -x, mean), std=[1, 1, 1]),\n",
    "                        transforms.Lambda(clip),\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.CenterCrop(224)])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(tf(pert_image.cpu()[0]))\n",
    "plt.title(str_label_pert)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
